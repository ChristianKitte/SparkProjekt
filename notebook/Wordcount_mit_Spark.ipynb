{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wordcount_mit_Spark",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuNFsvk+ma9sEMae+HU7zh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristianKitte/SparkProjekt/blob/main/notebook/Wordcount_mit_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJtej7pTMlmr"
      },
      "source": [
        "# Vorbereitung des Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VREA6gqNAMs8",
        "outputId": "86c9581b-68ec-42ec-abca-a8889e580ced"
      },
      "source": [
        "# Installation  von Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "print(\"Java ist installiert...\")\n",
        "\n",
        "# Download und Entpacken von Spark (Versionsnummer anpassen!)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "\n",
        "print(\"Spark ist verfügbar...\")\n",
        "\n",
        "# Setzen der Systemvariablen für Java und Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\"\n",
        "\n",
        "print(\"Umgebungsvariablen sind gesetzt...\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Java ist installiert...\n",
            "Spark ist verfügbar...\n",
            "Umgebungsvariablen sind gesetzt...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWPQDeb8bl9M",
        "outputId": "b7bc8341-d8b1-4f23-8a42-dce539cae5c0"
      },
      "source": [
        "!pip install findspark\n",
        "print(\"FindSpark wurde installiert...\")\n",
        "\n",
        "!pip install pyspark\n",
        "print(\"PySpark wurde installiert...\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (1.4.2)\n",
            "FindSpark wurde installiert...\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n",
            "PySpark wurde installiert...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9u5_oWDb7sw",
        "outputId": "db5f2b55-b6be-44da-8cc2-ca206d6d3e2f"
      },
      "source": [
        "try: \n",
        "  import findspark\n",
        "  from pyspark import SparkContext, SparkConf\n",
        "  \n",
        "  findspark.init()\n",
        "  \n",
        "  print(\"FindSpark und PySpark wurden initialisiert\")\n",
        "except ImportError: \n",
        "  raise ImportError(\"Fehler bei der Initialiserung von FindSpark und PySpark\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FindSpark und PySpark wurden initialisiert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjc0YuSDjZvn"
      },
      "source": [
        "# Einlesen der Textdatei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNaQNN9jkIie",
        "outputId": "a935b0a1-b944-4661-ef56-eb13fc483b60"
      },
      "source": [
        "import requests \n",
        "\n",
        "def get_file_from_url(file_url, place_to_save):\n",
        "  req = requests.get(file_url, stream = True) \n",
        "\n",
        "  with open(place_to_save, \"wb\") as file: \n",
        "\t  for block in req.iter_content(chunk_size = 1024): \n",
        "\t\t  if block: \n",
        "\t\t\t  file.write(block) \n",
        "     \n",
        "  print(\"Die Datei wurde angelegt: \", file_url)\n",
        "\n",
        "print(\"Die Funktion get_file_from_url wurde angelegt...\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Funktion get_file_from_url wurde angelegt...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf1_kePZkL4_",
        "outputId": "f87bf63b-716e-4fe8-fb72-8f87e9b517a1"
      },
      "source": [
        "def cut_file(start, end, file, backup):\n",
        "  try:\n",
        "    with open(file, \"r\") as source:\n",
        "      lines = source.readlines()\n",
        "    \n",
        "    source.close()\n",
        "  \n",
        "    start_count = start\n",
        "    end_count = end\n",
        "\n",
        "    print(\"Start: \", start_count)\n",
        "    print(\"Ende: \", end_count)\n",
        "\n",
        "    current_count = 0\n",
        "  \n",
        "    with open(backup, \"w\") as target:\n",
        "      for line in lines:\n",
        "        if current_count >= start_count and current_count <= end_count:\n",
        "          target.write(line)\n",
        "\n",
        "        current_count = current_count + 1   \n",
        "    \n",
        "    target.close()\n",
        "\n",
        "    print(\"Fertig...\")\n",
        "\n",
        "  except ValueError:\n",
        "    print(\"Fehler\",ValueError)\n",
        "\n",
        "print(\"Die Funktion cut_file wurde angelegt...\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Funktion cut_file wurde angelegt...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Nub_qSjiYZ"
      },
      "source": [
        "file_url = \"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\"\n",
        "place_to_save = \"/content/shakespeare.txt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9qv_PqBlOVt",
        "outputId": "d98ec1cf-06f5-4981-82d5-d3b23b7f5367"
      },
      "source": [
        "# Datei von der Quelle nach Colab laden\n",
        "\n",
        "file_url = \"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\"\n",
        "place_to_save = \"/content/shakespeare.txt\"\n",
        "\n",
        "get_file_from_url(file_url, place_to_save)\n",
        "\n",
        "print(\"Datei wurde geladen: \", file_url)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Datei wurde angelegt:  https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\n",
            "Datei wurde geladen:  https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HObiLObj8Yi",
        "outputId": "c332229f-9d20-417f-d7ac-8d45d4f0f458"
      },
      "source": [
        "# Unnötige Zeilen am Ende und am Start entfernen\n",
        "\n",
        "file_source = \"/content/shakespeare.txt\"\n",
        "file_target = \"/content/shakespeare_neu.txt\"\n",
        "\n",
        "cut_file(244,124438,file_source, file_target)\n",
        "\n",
        "print(\"Datei wurde beschnitten...\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start:  244\n",
            "Ende:  124438\n",
            "Fertig...\n",
            "Datei wurde beschnitten...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6HwX_ITMzWh"
      },
      "source": [
        "# Auszählen der Wörter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ikM4w-OlR7n",
        "outputId": "c41df7cb-df22-4d7f-ca1f-800fb58ac0bb"
      },
      "source": [
        "from pyspark import SparkContext \n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext \n",
        "from pyspark.sql import DataFrameReader\n",
        "\n",
        "\n",
        "#sc = SparkContext(\"local[3]\",\"word_count\")\n",
        "#sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "#from pyspark.sql import SparkSession\n",
        "#spark=SparkSession.builder.appName('Basics').getOrCreate()\n",
        "\n",
        "#Version 1\n",
        "#spark=SparkSession.builder.appName('WordCounter').getOrCreate()\n",
        "#sc = spark.sparkContext()\n",
        "\n",
        "#Version 2\n",
        "#sc = SparkContext(\"local[3]\",\"WordCounter\")\n",
        "#sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "lines=sc.textFile(file_target).map( lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower()).filter(lambda linex: linex.strip() != \"\") \n",
        "for line in lines.collect()[0:30]:\n",
        "  print(line) \n",
        "\n",
        "#print(\"Zeilen: \" + str(lines.count()))\n",
        "\n",
        "words=lines.flatMap(lambda line: line.split(\" \")) \\\n",
        "  .map(lambda word: (word, 1)) \\\n",
        "  .reduceByKey(lambda a,b:a+b)\n",
        "\n",
        "#for x in words[0:20]:\n",
        "#  print(x)\n",
        "\n",
        "#print(words.first)\n",
        "sorted_counts = words.sortBy(lambda wordCounts: wordCounts[1], ascending=False)\n",
        "\n",
        "#print(\"Wörter: \" + str(words.count()))\n",
        "\n",
        "#y=words.sortBy(lambda wc:wc[1], ascending=False)\n",
        "\n",
        "#wordCounts=words.countByValue()\n",
        "#print(\"Anzahl der unterschiedlichen Wörter: \"+ str(len(wordCounts.items())))\n",
        "\n",
        "#for word, count in words.collect()[0:10]:\n",
        "#  print(\"Wort: {} - Anzahl: {}\".format(word, count)) \n",
        "\n",
        "i = 0\n",
        "for word, count in sorted_counts.collect()[0:30]:\n",
        "    print(\"{} : {} : {} \".format(i, word, count))\n",
        "    i += 1"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1609\n",
            "the sonnets\n",
            "by william shakespeare\n",
            "                     1\n",
            "  from fairest creatures we desire increase \n",
            "  that thereby beauty's rose might never die \n",
            "  but as the riper should by time decease \n",
            "  his tender heir might bear his memory:\n",
            "  but thou contracted to thine own bright eyes \n",
            "  feed'st thy light's flame with self substantial fuel \n",
            "  making a famine where abundance lies \n",
            "  thy self thy foe  to thy sweet self too cruel:\n",
            "  thou that art now the world's fresh ornament \n",
            "  and only herald to the gaudy spring \n",
            "  within thine own bud buriest thy content \n",
            "  and tender churl mak'st waste in niggarding:\n",
            "    pity the world  or else this glutton be \n",
            "    to eat the world's due  by the grave and thee \n",
            "                     2\n",
            "  when forty winters shall besiege thy brow \n",
            "  and dig deep trenches in thy beauty's field \n",
            "  thy youth's proud livery so gazed on now \n",
            "  will be a tattered weed of small worth held:  \n",
            "  then being asked  where all thy beauty lies \n",
            "  where all the treasure of thy lusty days;\n",
            "  to say within thine own deep sunken eyes \n",
            "  were an all eating shame  and thriftless praise \n",
            "  how much more praise deserved thy beauty's use \n",
            "  if thou couldst answer 'this fair child of mine\n",
            "  shall sum my count  and make my old excuse'\n",
            "0 :  : 669971 \n",
            "1 : the : 27507 \n",
            "2 : and : 26705 \n",
            "3 : i : 20191 \n",
            "4 : to : 19294 \n",
            "5 : of : 18076 \n",
            "6 : a : 14502 \n",
            "7 : you : 12957 \n",
            "8 : my : 12468 \n",
            "9 : that : 10950 \n",
            "10 : in : 10903 \n",
            "11 : is : 9473 \n",
            "12 : not : 8443 \n",
            "13 : for : 8181 \n",
            "14 : with : 7965 \n",
            "15 : it : 7212 \n",
            "16 : be : 6963 \n",
            "17 : me : 6962 \n",
            "18 : your : 6865 \n",
            "19 : his : 6825 \n",
            "20 : this : 6276 \n",
            "21 : but : 6267 \n",
            "22 : he : 6102 \n",
            "23 : as : 5927 \n",
            "24 : have : 5838 \n",
            "25 : thou : 5378 \n",
            "26 : so : 4948 \n",
            "27 : will : 4858 \n",
            "28 : him : 4625 \n",
            "29 : by : 4386 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e3JXQuBM4-c",
        "outputId": "38ab0f12-73ca-493b-ac59-8e602a24693f"
      },
      "source": [
        "print(\"...hier kommt der weitere Code\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...hier kommt der weitere Code\n"
          ]
        }
      ]
    }
  ]
}